{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningANN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7GE_XC_Bs1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fb5c8dd8-11fb-4143-ffe2-80023fb48493"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "data=pd.read_csv('datasets_180_408_data.csv')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw6isac2Ca1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "a280726f-5453-4483-9f5b-5dbae50ac1ea"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61QXd2WuCd_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del data['Unnamed: 32']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xMOK0eCCjdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=data.iloc[:,2:].values\n",
        "y=data.iloc[:,1].values\n",
        "\n",
        "#Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=labelencoder.fit_transform(y)\n",
        "\n",
        "#Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=0)\n",
        "\n",
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.fit_transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU5ItsBsEnj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import Keras\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcHp0wA4F6io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier=Sequential()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKYjxtiIF9oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding the input layer and the first hidden layer\n",
        "\n",
        "classifier.add(Dense(16, activation='relu', input_dim=30,kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dropout(0.1))\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y1Fm4mZN7Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding the second layer\n",
        "\n",
        "classifier.add(Dense(16, activation='relu', input_dim=30,kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dropout(0.1))\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOhh8RvgPzvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding the output layer\n",
        "classifier.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbNSMVyaQQ3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compiling the ANN\n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vUqZmaKQwvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d8b581d-dc07-49ea-f3e1-04494af580b9"
      },
      "source": [
        "#fitting the ANN to training set\n",
        "classifier.fit(X_train,y_train,batch_size=100,epochs=150)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5605\n",
            "Epoch 2/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.6328\n",
            "Epoch 3/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.6484\n",
            "Epoch 4/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6875\n",
            "Epoch 5/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.7812\n",
            "Epoch 6/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.8652\n",
            "Epoch 7/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.9121\n",
            "Epoch 8/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.9355\n",
            "Epoch 9/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.9453\n",
            "Epoch 10/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.9473\n",
            "Epoch 11/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.9570\n",
            "Epoch 12/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.9551\n",
            "Epoch 13/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.9590\n",
            "Epoch 14/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.9570\n",
            "Epoch 15/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9609\n",
            "Epoch 16/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.9629\n",
            "Epoch 17/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9648\n",
            "Epoch 18/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9707\n",
            "Epoch 19/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.1009 - accuracy: 0.9668\n",
            "Epoch 20/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9727\n",
            "Epoch 21/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9727\n",
            "Epoch 22/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9707\n",
            "Epoch 23/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9746\n",
            "Epoch 24/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9746\n",
            "Epoch 25/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9785\n",
            "Epoch 26/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9824\n",
            "Epoch 27/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9844\n",
            "Epoch 28/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9824\n",
            "Epoch 29/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9766\n",
            "Epoch 30/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9805\n",
            "Epoch 31/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9844\n",
            "Epoch 32/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9824\n",
            "Epoch 33/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9844\n",
            "Epoch 34/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9824\n",
            "Epoch 35/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9844\n",
            "Epoch 36/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9844\n",
            "Epoch 37/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9844\n",
            "Epoch 38/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9805\n",
            "Epoch 39/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9844\n",
            "Epoch 40/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9824\n",
            "Epoch 41/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9863\n",
            "Epoch 42/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9824\n",
            "Epoch 43/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9883\n",
            "Epoch 44/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9863\n",
            "Epoch 45/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9863\n",
            "Epoch 46/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9863\n",
            "Epoch 47/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9883\n",
            "Epoch 48/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9883\n",
            "Epoch 49/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9883\n",
            "Epoch 50/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9902\n",
            "Epoch 51/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9883\n",
            "Epoch 52/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9844\n",
            "Epoch 53/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9824\n",
            "Epoch 54/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9824\n",
            "Epoch 55/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9863\n",
            "Epoch 56/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9844\n",
            "Epoch 57/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9902\n",
            "Epoch 58/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9902\n",
            "Epoch 59/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9883\n",
            "Epoch 60/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9883\n",
            "Epoch 61/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9844\n",
            "Epoch 62/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9902\n",
            "Epoch 63/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9824\n",
            "Epoch 64/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9902\n",
            "Epoch 65/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9863\n",
            "Epoch 66/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9844\n",
            "Epoch 67/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9883\n",
            "Epoch 68/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9883\n",
            "Epoch 69/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9883\n",
            "Epoch 70/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9883\n",
            "Epoch 71/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9922\n",
            "Epoch 72/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9902\n",
            "Epoch 73/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9883\n",
            "Epoch 74/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9902\n",
            "Epoch 75/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9922\n",
            "Epoch 76/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9902\n",
            "Epoch 77/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9902\n",
            "Epoch 78/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9902\n",
            "Epoch 79/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9863\n",
            "Epoch 80/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9902\n",
            "Epoch 81/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9902\n",
            "Epoch 82/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9902\n",
            "Epoch 83/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9883\n",
            "Epoch 84/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9922\n",
            "Epoch 85/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9902\n",
            "Epoch 86/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9902\n",
            "Epoch 87/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9902\n",
            "Epoch 88/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9902\n",
            "Epoch 89/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9902\n",
            "Epoch 90/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9883\n",
            "Epoch 91/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9922\n",
            "Epoch 92/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9902\n",
            "Epoch 93/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9883\n",
            "Epoch 94/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9922\n",
            "Epoch 95/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9902\n",
            "Epoch 96/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9922\n",
            "Epoch 97/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9922\n",
            "Epoch 98/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9922\n",
            "Epoch 99/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9922\n",
            "Epoch 100/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9922\n",
            "Epoch 101/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9922\n",
            "Epoch 102/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9922\n",
            "Epoch 103/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9902\n",
            "Epoch 104/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9902\n",
            "Epoch 105/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9922\n",
            "Epoch 106/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9922\n",
            "Epoch 107/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9922\n",
            "Epoch 108/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9922\n",
            "Epoch 109/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9922\n",
            "Epoch 110/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9902\n",
            "Epoch 111/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9922\n",
            "Epoch 112/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9922\n",
            "Epoch 113/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9902\n",
            "Epoch 114/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9922\n",
            "Epoch 115/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9922\n",
            "Epoch 116/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9883\n",
            "Epoch 117/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9922\n",
            "Epoch 118/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9922\n",
            "Epoch 119/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9902\n",
            "Epoch 120/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9902\n",
            "Epoch 121/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9902\n",
            "Epoch 122/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9922\n",
            "Epoch 123/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9922\n",
            "Epoch 124/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9922\n",
            "Epoch 125/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9902\n",
            "Epoch 126/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9922\n",
            "Epoch 127/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9922\n",
            "Epoch 128/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9902\n",
            "Epoch 129/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9922\n",
            "Epoch 130/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9922\n",
            "Epoch 131/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9922\n",
            "Epoch 132/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9902\n",
            "Epoch 133/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9922\n",
            "Epoch 134/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9922\n",
            "Epoch 135/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9922\n",
            "Epoch 136/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9922\n",
            "Epoch 137/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9922\n",
            "Epoch 138/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9902\n",
            "Epoch 139/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9922\n",
            "Epoch 140/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 0.9922\n",
            "Epoch 141/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9922\n",
            "Epoch 142/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9922\n",
            "Epoch 143/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9922\n",
            "Epoch 144/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9922\n",
            "Epoch 145/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9922\n",
            "Epoch 146/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9922\n",
            "Epoch 147/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9902\n",
            "Epoch 148/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9922\n",
            "Epoch 149/150\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9922\n",
            "Epoch 150/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f130b04c5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kipjKZ19REbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=classifier.predict(X_test)\n",
        "y_pred=(y_pred>0.5)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30WdlDyzRwGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "99d7406a-da47-4626-aebb-03ae7ede2c49"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8LytQZVSFoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcy7Q4h6TWNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "722923c0-cdd0-4cbf-8e0a-ccc82af04fb6"
      },
      "source": [
        "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/57)*100))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our accuracy is 94.73684210526315%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjgCtmWnTZad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e4520e2a-2217-4b20-ce4f-3713ff910185"
      },
      "source": [
        "sns.heatmap(cm,annot=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1308967160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf-M3zxmTdl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}